#+TITLE: Repeat Masking Pipeline
#+HTML_HEAD: <link href="./theme.css" rel="stylesheet">

* Installing

  Ideally, the only prerequisites would be [[https://www.nextflow.io/][Nextflow]] and
  [[https://www.docker.com/][Docker]]. Unfortunately, it's almost impossible to do work on repeats
  without the RepBase library which carries licence restrictions so
  I'm unable to include the library in the Docker image.

  To build your own image that /does/ include the RepBase libraries,
  run:

  #+BEGIN_SRC sh
    cd `mktemp -d`

    # Download the RepBase repeat library (replace RB_USERNAME and RB_PASSWORD with your username and password)
    wget --user $RB_USERNAME \
         --password $RB_PASSWORD \
         --output-document repeatmaskerlibraries.tar.gz \
         http://www.girinst.org/server/RepBase/protected/repeatmaskerlibraries/repeatmaskerlibraries-20140131.tar.gz

    # Make an (almost) empty Dockerfile.
    #  All of the important instructions are in the repeatmasker-onbuild image
    #  You can view them here: https://github.com/robsyme/nextflow-annotate/blob/master/Dockerfiles/RepeatMasker-onbuild/Dockerfile
    echo "FROM robsyme/nf-repeatmasking-onbuild" > Dockerfile

    # Build a new docker image called 'nf-repeatmasking'.
    #  When building, this image looks for a file called 'repeatmaskerlibraries.tar.gz' which it pulls into the image.
    docker build -t robsyme/nf-repeatmasking .
  #+END_SRC

* Walkthrough
** Introduction
   This is a [[https://en.wikipedia.org/wiki/Literate_programming][literate-programming]] style walk through the pipeline,
   explaining the utility of every section. Each code block below gets
   tangled to compose the  pipline, which is written out to [[file:../main.nf][=main.nf=]].
** Parameter Setup

   There is some necessary setup and housekeeping to begin. This is
   where we set up our strain name, the path to our reference sequence
   and the output location for our final figures and tables.

   #+BEGIN_SRC groovy :tangle ../main.nf :shebang #!/usr/bin/env nextflow
         VERSION = "1.0.0"

         params.reference = 'data/example/genome.fasta'
         params.trnaprot = 'http://www.hrt.msu.edu/uploads/535/78637/Tpases020812.gz'
         params.trnanuc = 'http://gtrnadb2009.ucsc.edu/download/tRNAs/eukaryotic-tRNAs.fa.gz'
         params.outdir = 'output'
         params.minRepLength = 250

         trnanuc = file(params.trnanuc)
         trnaprot = file(params.trnaprot)
         reference = file(params.reference)

         log.info ""
         log.info "R E P E A T M A S K I N G  ~  version " + VERSION
         log.info "reference input    : ${params.reference}"
         log.info "output directory   : ${params.outdir}"
         log.info ""
   #+END_SRC

** Collection of relatively recent LTR retrotranposons

    The rationale for initial collection of recent LTR elements is
    that these elements contain less nested insertions and mutations
    as well as recombination, thus the chance for false positives is
    relatively low. We use the ltrharvest command from [[http://genometools.org][genometools]] to
    collect potential LTR sequences with the following
    characteristics:

    - Two terminal repeats which are >= 99% similar, ranging from 100 bp tp 6000 bp
    - The two terminal repeats end with “TG…CA”
    - The size of entire element ranges from 1.5 kb to 25 kb
    - The element must be flanked by a 5bp TSD (target site duplication)
    - The TSD is within 10 bp from the end of the element

    The results are then passed through =ltrdigest= (again, from
    genometools) to retain only those elements with polypurine tract
    (PPT) and primer binding site (PBS).

    The =CRL_Step1= script ensures that at least 50% of the PPT or PBS
    sequences are located in the internal regions and the distance
    between LTR and PPT or PBS are no more than 20 bp.

    The =CRL_Step2= script filters again. False positives due to gene
    clusters may still linger in the output from =CRL_Step1=. These
    instances will have alignable regions that extend past the LTR
    boundary. We pull out the flanking sequence from the putative LTR,
    and if the flanking sequence /also/ aligns, we discard it.

    #+BEGIN_SRC groovy :tangle ../main.nf
      process recentLTRs {
        container 'robsyme/nf-repeatmasking'
        cache 'deep'

        input:
        file 'genome.fasta' from reference
        file 'eukaryotic-tRNAs.fasta.gz' from trnanuc

        output:
        set age, 'seqfile.result' into ltrHarvestResultsNew
        set age, 'seqfile.result' into ltrHarvestResultsForExemplarNew
        set age, 'seqfile.outinner' into ltrHarvestInnerNew
        set age, 'seqfile.outinner' into outinnerForBlastXNew
        set age, 'CRL_Step2_Passed_Elements.fasta', 'Repeat_down*.fasta', 'Repeat_up*.fasta' into recentLTRs

        script:
        age = 'new'
        """
      gt suffixerator -db genome.fasta -indexname genome.fasta -tis -suf -lcp -des -ssp -dna

      gt ltrharvest \
       -index genome.fasta \
       -out seqfile.out \
       -outinner seqfile.outinner \
       -gff3 seqfile.gff \
       -minlenltr 100 \
       -maxlenltr 6000 \
       -mindistltr 1500 \
       -maxdistltr 25000 \
       -mintsd 5 \
       -maxtsd 5 \
       -motif tgca \
       -similar 99 \
       -vic 10 \
      > seqfile.result

      gt gff3 \
       -sort seqfile.gff \
      > seqfile.gff.sort

      zcat eukaryotic-tRNAs.fasta.gz > eukaryotic-tRNAs.fasta

      gt ltrdigest \
       -trnas eukaryotic-tRNAs.fasta \
       seqfile.gff.sort \
       genome.fasta \
      > seqfile.gff.dgt

      CRL_Step1.pl \
       --gff seqfile.gff.dgt

      CRL_Step2.pl \
       --step1 CRL_Step1_Passed_Elements.txt \
       --repeatfile seqfile.out \
       --resultfile seqfile.result \
       --sequencefile genome.fasta \
       --removed_repeats CRL_Step2_Passed_Elements.fasta
        """
      }
    #+END_SRC

** Collection of relatively old LTR retrotransposons

    Collection of relatively old LTRs is enabled by reducing the
    similarity between LTRs to 85% (default value of LTRharvest) and
    not associated with terminal sequence motif (but the process is
    otherwise identical to =recentLTRs=).

    #+BEGIN_SRC groovy :tangle ../main.nf
      process olderLTRs {
        container 'robsyme/nf-repeatmasking'
        cache 'deep'

        input:
        file 'genome.fasta' from reference
        file 'eukaryotic-tRNAs.fasta.gz' from trnanuc

        output:
        set age, 'seqfile.result' into ltrHarvestResultsOld
        set age, 'seqfile.result' into ltrHarvestResultsForExemplarOld
        set age, 'seqfile.outinner' into ltrHarvestInnerOld
        set age, 'seqfile.outinner' into outinnerForBlastXOld
        set age, 'CRL_Step2_Passed_Elements.fasta', 'Repeat_down*.fasta', 'Repeat_up*.fasta' into olderLTRs

        script:
        age = 'old'
        """
      gt suffixerator -db genome.fasta -indexname genome.fasta -tis -suf -lcp -des -ssp -dna

      gt ltrharvest \
       -index genome.fasta \
       -out seqfile.out \
       -outinner seqfile.outinner \
       -gff3 seqfile.gff \
       -minlenltr 100 \
       -maxlenltr 6000 \
       -mindistltr 1500 \
       -maxdistltr 25000 \
       -mintsd 5 \
       -maxtsd 5 \
       -vic 10 \
      > seqfile.result

      gt gff3 \
       -sort seqfile.gff \
      > seqfile.gff.sort

      zcat eukaryotic-tRNAs.fasta.gz > eukaryotic-tRNAs.fasta

      gt ltrdigest \
       -trnas eukaryotic-tRNAs.fasta \
       seqfile.gff.sort \
       genome.fasta \
      > seqfile.gff.dgt

      CRL_Step1.pl \
       --gff seqfile.gff.dgt

      CRL_Step2.pl \
       --step1 CRL_Step1_Passed_Elements.txt \
       --repeatfile seqfile.out \
       --resultfile seqfile.result \
       --sequencefile genome.fasta \
       --removed_repeats CRL_Step2_Passed_Elements.fasta
        """
      }
    #+END_SRC

** Cleaning LTR results

    LTRs (both new and old) identified above will almost certainly
    include false positives that need to be removed. The most common
    errors are:

    - Tandem local repeats (such as centromeric repeats)
    - Local gene clusters derived from gene duplications

    In the case of genuine LTRs, the insertion site will differ
    between LTR instances. The result is that alignment between two
    instances will not extend past the borders of the terminal repeat
    regions. In false positive instances like the examples above, the
    alignability of the instances may extend past the terminal
    repeats. :TODO: Present dot-plot examples of true and false LTRs.

    The outupt of this process (=CRL_Step3_Passed_Elements.fasta=) is
    a FASTA file containing element sequences that have passed the
    percent identity (60%) and number of identical nucleotides
    thresholds.

    #+BEGIN_SRC groovy :tangle ../main.nf
      ltrs = recentLTRs.mix(olderLTRs)
      ltrHarvestResults = ltrHarvestResultsOld.mix(ltrHarvestResultsNew)
      ltrHarvestInner = ltrHarvestInnerOld.mix(ltrHarvestInnerNew)
      outinnerForBlastX = outinnerForBlastXOld.mix(outinnerForBlastXNew)
      ltrHarvestResultsForExemplar = ltrHarvestResultsForExemplarOld.mix(ltrHarvestResultsForExemplarNew)
    #+END_SRC

    #+BEGIN_SRC groovy :tangle ../main.nf
      process CRL_Step3 {
        container 'robsyme/nf-repeatmasking'
        tag { age }

        input:
        set age, 'CRL_Step2_Passed_Elements.fasta', 'Repeat_down*.fasta', 'Repeat_up*.fasta' from ltrs

        output:
        set age, 'CRL_Step3_Passed_Elements.fasta' into step3Passed
        set age, 'CRL_Step3_Passed_Elements.fasta' into step3PassedForExemplars

        """
      CRL_Step3.pl \
       --directory . \
       --step2 CRL_Step2_Passed_Elements.fasta \
       --pidentity 60 \
       --seq_c 25
        """
      }
    #+END_SRC

    Retrotranposons are frequently nested with each other or inserted
    by other elements. If left unidentified, it will cause
    misclassification and other complications. To detect those
    elements, LTR sequences from candidate elements retained after
    steps in 2.1.3 are used to mask the putative internal regions. If
    LTR sequences are detected in the internal regions, it is
    considered as elements nested with other insertions.

    The internal regions of elements are also used to search against
    a transposase database of DNA transposons. If the internal
    sequence has significant matches with any DNA transposase, it is
    considered as an element containing nested insertions.

    This process produces =lLTR_Only.lib=, a FASTA file containing
    the sequence of the left (5'end) LTR sequence.

    #+BEGIN_SRC groovy :tangle ../main.nf
      ltrHarvestResults
      .combine(step3Passed, by: 0)
      .set { nestedInput }

      process identifyNestedInsetions {
        container 'robsyme/nf-repeatmasking'
        tag { age }
        input:
        file 'genome.fasta' from reference
        set age, 'seqfile.result', 'CRL_Step3_Passed_Elements.fasta' from nestedInput

        output:
        set age, 'repeats_to_mask_LTR.fasta' into repeatsToMaskLTR

        """
      ltr_library.pl \
       --resultfile seqfile.result \
       --step3 CRL_Step3_Passed_Elements.fasta \
       --sequencefile genome.fasta
      cat lLTR_Only.lib \
      | awk 'BEGIN {RS = ">" ; FS = "\\n" ; ORS = ""} \$2 {print ">"\$0}' \
      > repeats_to_mask_LTR.fasta
        """
      }
    #+END_SRC

** Identify elements with nested insertions

   Retrotranposons are frequently nested with each other or inserted
   by other elements. If left unidentified, it will cause
   misclassification and other complications. To detect those
   elements, LTR sequences from candidate elements retained after
   steps in == are used to mask the putative internal regions. If
   LTR sequences are detected in the internal regions, it is
   considered as elements nested with other insertions.

   #+BEGIN_SRC groovy :tangle ../main.nf
     process RepeatMasker1 {
       container 'robsyme/nf-repeatmasking'
       tag { age }

       input:
       set age, 'repeats_to_mask_LTR.fasta', 'seqfile.outinner' from repeatsToMaskLTR.combine(ltrHarvestInner, by: 0)

       output:
       set age, 'seqfile.outinner.out', 'seqfile.outinner.masked' into repeatMasker1Unclean

       """
     RepeatMasker \
      -lib repeats_to_mask_LTR.fasta \
      -nolow \
      -no_is \
      -dir . \
      seqfile.outinner

     if [ ! -f seqfile.outinner.masked ]; then
       cp seqfile.outinner seqfile.outinner.masked
     fi
       """
     }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     process cleanRM {
       tag { age }

       input:
       set age, 'seqfile.outinner.out', 'seqfile.outinner.masked' from repeatMasker1Unclean

       output:
       set age, 'seqfile.outinner.clean' into repeatMasker1Clean

       """
     cleanRM.pl seqfile.outinner.out seqfile.outinner.masked > seqfile.outinner.unmasked
     rmshortinner.pl seqfile.outinner.unmasked 50 > seqfile.outinner.clean
       """
     }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     process blastX {
       container 'robsyme/nf-repeatmasking'
       tag { age }
       cpus 4

       input:
       file 'Tpases020812DNA.fasta.gz' from trnaprot
       set age, 'seqfile.outinner.clean', 'seqfile.outinner' from repeatMasker1Clean.combine(outinnerForBlastX, by: 0)

       output:
       set age, 'passed_outinner_sequence.fasta' into blastxPassed

       """
     zcat Tpases020812DNA.fasta.gz > Tpases020812DNA.fasta
     makeblastdb -in Tpases020812DNA.fasta -dbtype prot
     blastx \
      -query seqfile.outinner.clean \
      -db Tpases020812DNA.fasta \
      -evalue 1e-20 \
      -num_descriptions 10 \
      -num_threads ${task.cpus} \
      -out seqfile.outinner.clean_blastx.out.txt

     outinner_blastx_parse.pl \
      --blastx seqfile.outinner.clean_blastx.out.txt \
      --outinner seqfile.outinner

     if [ ! -s passed_outinner_sequence.fasta ]; then
       echo -e '>dummy empty sequence\nACTACTAC' > passed_outinner_sequence.fasta
     fi
       """
     }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     blastxPassed
     .combine(step3PassedForExemplars, by: 0)
     .combine(ltrHarvestResultsForExemplar, by: 0)
     .set { forExemplarBuilding }

     process buildExemplars {
       container 'robsyme/nf-repeatmasking'
       tag { age }
       cpus 4

       input:
       file 'genome.fasta' from reference
       set age, 'passed_outinner_sequence.fasta', 'CRL_Step3_Passed_Elements.fasta', 'seqfile.result' from forExemplarBuilding

       output:
       set age, 'LTR.lib' into exemplars

       """
     CRL_Step4.pl \
      --step3 CRL_Step3_Passed_Elements.fasta \
      --resultfile seqfile.result \
      --innerfile passed_outinner_sequence.fasta \
      --sequencefile genome.fasta

     for lib in lLTRs_Seq_For_BLAST.fasta Inner_Seq_For_BLAST.fasta; do
       makeblastdb -in \$lib -dbtype nucl
       blastn \
        -query \${lib} \
        -db \${lib} \
        -evalue 1e-10 \
        -num_threads ${task.cpus} \
        -num_descriptions 1000 \
        -out \${lib}.out
     done

     CRL_Step5.pl \
      --LTR_blast lLTRs_Seq_For_BLAST.fasta.out \
      --inner_blast Inner_Seq_For_BLAST.fasta.out \
      --step3 CRL_Step3_Passed_Elements.fasta \
      --final LTR.lib \
      --pcoverage 90 \
      --pidentity 80
       """
     }
   #+END_SRC

   Since the set of older LTR elements contain elements from the
   newer LTR set, the exemplar sequences need to be masked by
   LTR99.lib and all elements that are significantly masked (cutoff
   at 80% identity in 90% of the element length) are excluded.

   #+BEGIN_SRC groovy :tangle ../main.nf
     newLTRs = Channel.create()
     oldLTRs = Channel.create()

     exemplars
     .choice( newLTRs, oldLTRs ) { it[0] == "new" ? 0 : 1 }

     process removeDuplicates {
       container 'robsyme/nf-repeatmasking'

       input:
       set _, 'ltrs.new.fasta' from newLTRs
       set _, 'ltrs.old.fasta' from oldLTRs

       output:
       set 'ltrs.old.fasta.masked', 'ltrs.new.fasta' into bothLTRforMasking

       "RepeatMasker -lib ltrs.new.fasta -dir . ltrs.old.fasta"
     }

     process filterOldLTRs {
       container 'robsyme/nf-repeatmasking'

       input:
       set 'ltrs.old.fasta.masked', 'ltrs.new.fasta' from bothLTRforMasking

       output:
       file 'allLTRs.fasta' into allLTR

       """
     remove_masked_sequence.pl \
     --masked_elements ltrs.old.fasta.masked \
     --outfile ltrs.old.final.fasta
     cat ltrs.new.fasta ltrs.old.final.fasta > allLTRs.fasta
       """
     }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     allLTR
     .splitFasta(record: [id: true, sequence: true ])
     .collectFile( name: 'allLTRs.fasta' ) { ">" + it.id + "#LTR\n" + it.sequence }
     .tap { allLTR2 }
     .set { inputForRM2 }

     process RepeatMasker2 {
       container 'robsyme/nf-repeatmasking'
       cpus 10

       input:
       file 'genome.fasta' from reference
       file 'allLTR.lib' from inputForRM2

       output:
       file 'genome.fasta.masked' into genomeLtrMasked

       """
     RepeatMasker \
      -no_is \
      -nolow \
      -pa ${task.cpus} \
      -lib allLTR.lib \
      -dir . \
      genome.fasta
       """
     }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     process RepeatModeler {
       container 'robsyme/nf-repeatmasking'
       cpus 4

       input:
       file 'genome.masked' from genomeLtrMasked

       output:
       file 'consensi.fa.classified' into rmOutput

       """
     rmaskedpart.pl genome.masked 50 | sed '/^\$/d' > umseqfile
     BuildDatabase -name umseqfiledb -engine ncbi umseqfile
     RepeatModeler -pa ${task.cpus} -database umseqfiledb >& umseqfile.out
     mv RM*/consensi.fa.classified consensi.fa.classified
       """
     }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     identityUnknown = Channel.create()
     identityKnown = Channel.create()

     rmOutput
     .splitFasta(record: [id: true, text: true])
     .choice(identityUnknown, identityKnown) { record -> record.id =~ /#Unknown/ ? 0 : 1 }

     identityUnknown
     .collectFile() { record -> ['unknown.fasta', record.text] }
     .set { repeatmaskerUnknowns }

     identityKnown
     .collectFile() { record -> ['known.fasta', record.text] }
     .tap { repeatmaskerKnowns1 }
     .set{ repeatmaskerKnowns }
   #+END_SRC

   We'd like to get a better idea about what these 'unknown elements'
   are. It's possible that they are known transposons that have been
   RIPped beyond recognition. To retrieve these, we can pull out an
   alignment of these repeat instances (with RepeatMasker), run [[https://bmcgenomics.biomedcentral.com/articles/10.1186/1471-2164-11-655][DeRIP]]
   over each alignment and then push them back into the identification
   pipeline (RepeatModeler classify script).

   #+BEGIN_SRC groovy :tangle ../main.nf
     process searchForUnidentifiedElements {
       container 'robsyme/nf-repeatmasking'

       input:
       file 'genome.fasta' from reference
       file 'unknown_elements.fasta' from repeatmaskerKnowns1

       output:
       set 'genome.fasta.align', 'unknown_elements.fasta' into unknownAlignments

       """
     RepeatMasker \
      -lib unknown_elements.fasta \
      -alignments \
      -nolow \
      -no_is \
      -dir . \
      -inv \
      genome.fasta
       """
     }

     process derip {
       container 'robsyme/nf-repeatmasking'

       input:
       set 'genome.fasta.align', 'unknown_elements.fasta' from unknownAlignments

       output:
       file 'deripped.unknowns.fasta' into derippedUnknowns

       """
     rmalignment_to_fasta.rb genome.fasta.align unknown_elements.fasta
     for file in alignment*; do
       derip.rb \$file
     done > deripped.unknowns.fasta
       """
     }

     process classifyDeripped {
       container 'repeats'

       input:
       file 'transposases.fasta.gz' from trnaprot
       file 'repeatmodeler_unknowns.deripped.fasta' from derippedUnknowns

       output:
       file 'identified_elements.txt' into identifiedDerippedTransposons
       file 'unknown_elements.txt' into unidentifiedDerippedTransposons

       """
     zcat transposases.fasta.gz > transposases.fasta
     makeblastdb \
      -in transposases.fasta \
      -dbtype prot
     blastx \
      -query repeatmodeler_unknowns.deripped.fasta \
      -db transposases.fasta \
      -evalue 1e-10 \
      -num_descriptions 10 \
      -num_threads ${task.cpus} \
      -out modelerunknown_blast_results.txt
     transposon_blast_parse.pl \
      --blastx modelerunknown_blast_results.txt \
      --modelerunknown repeatmodeler_unknowns.deripped.fasta
       """
     }

     identifiedDerippedTransposons.subscribe{ println("Identified, deripped: ${it}") }
   #+END_SRC

   Blast transposons against database of known elements:

   #+BEGIN_SRC groovy :tangle ../main.nf
     process transposonBlast {
       container 'robsyme/nf-repeatmasking'
       cpus 4

       input:
       file 'transposases.fasta.gz' from trnaprot
       file 'repeatmodeler_unknowns.fasta' from repeatmaskerUnknowns

       output:
       file 'identified_elements.txt' into identifiedTransposons
       file 'unknown_elements.txt' into unidentifiedTransposons

       """
     zcat transposases.fasta.gz > transposases.fasta
     makeblastdb \
      -in transposases.fasta \
      -dbtype prot
     blastx \
      -query repeatmodeler_unknowns.fasta \
      -db transposases.fasta \
      -evalue 1e-10 \
      -num_descriptions 10 \
      -num_threads ${task.cpus} \
      -out modelerunknown_blast_results.txt
     transposon_blast_parse.pl \
      --blastx modelerunknown_blast_results.txt \
      --modelerunknown repeatmodeler_unknowns.fasta
       """
     }

   #+END_SRC

** Noncoding RNA

   We'll borrow the excellent ncRNA prediction steps from the
   excellent [[https://github.com/sanger-pathogens/companion][Companion annotation pipeline]].

   #+BEGIN_SRC groovy :tangle ../main.nf
         process predict_ncRNA {
           container 'sangerpathogens/companion:latest'

           input:
           file 'genome.fasta' from reference

           output:
           file 'cm_out' into cmtblouts

           """
         cp /opt/data/cm/rnas.cm models.cm
         cmpress -F models.cm
         cmsearch --cpu 1 --tblout cm_out --cut_ga models.cm genome.fasta
           """
         }

         process merge_ncrnas {
           publishDir "${params.outdir}/noncoding-rna", mode: 'copy'
           container 'sangerpathogens/companion:latest'
           cache 'deep'

           input:
           file 'cmtblout' from cmtblouts

           output:
           file 'ncrna.gff3' into ncrnafile

           """
           infernal_to_gff3.lua < ${cmtblout} > 1
           gt gff3 -sort -tidy -retainids 1 > ncrna.gff3
           """
         }

         ncrnafile.println()
   #+END_SRC

** Final Masking

   #+BEGIN_SRC groovy :tangle ../main.nf
     repeatmaskerKnowns
     .mix(identifiedTransposons)
     .collectFile() { it.text }
     .combine(allLTR2)
     .set { knownRepeats }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
         process repeatMaskerKnowns {
           container 'robsyme/nf-repeatmasking'
           publishDir "${params.outdir}/repeatMaskerKnowns", mode: 'copy'

           input:
           file 'reference.fasta' from reference
           set 'knownTransposons.lib', 'allLTRs.lib' from knownRepeats

           output:
           set 'reference.fasta.out', 'reference.fasta.masked' into repeatMaskerKnownsMasked
           set 'reference.fasta.out.gff', 'knownRepeats.library.fasta'

           """
         cat *.lib > knownRepeats.library.fasta
         RepeatMasker \
          -lib knownRepeats.library.fasta \
          -nolow \
          -no_is \
          -dir . \
          -gff \
          -s \
          reference.fasta
           """
         }

         process removeShortMatches {
           container 'robsyme/nf-repeatmasking'
           publishDir "${params.outdir}/cleanMasked", mode: 'copy'

           input:
           file 'reference.fa' from reference
           set 'rm.out', 'rm.masked' from repeatMaskerKnownsMasked

           output:
           set 'rm.trimmed.out', 'rm.trimmed.masked' into repeatMaskerKnownsMaskedTrimmed

           """
         head -n 3 rm.out > rm.trimmed.out
         tail -n +4 rm.out | awk '\$7 - \$6 > ${params.minRepLength}' >> rm.trimmed.out
         tail -n +4 rm.out | awk 'BEGIN{OFS="\\t"} \$7 - \$6 > ${params.minRepLength} {print \$5, \$6, \$7}' >> rm.trimmed.bed
         maskFastaFromBed -fi reference.fa -bed rm.trimmed.bed -fo rm.trimmed.masked -soft
           """
         }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     process octfta {
       container 'robsyme/nf-repeatmasking'

       input:
       file 'reference.fa' from reference
       set 'rm.out', 'rm.masked' from repeatMaskerKnownsMaskedTrimmed

       output:
       file 'summary.tsv' into repeatmaskerSummaryTable

       """
     build_dictionary.pl --rm rm.out > ltr.dict
     one_code_to_find_them_all.pl --rm rm.out --ltr ltr.dict --fasta reference.fa
     echo -e 'Family\\tElement Length\\tFragments\\tCopies\\tSolo_LTR\\tTotal_Bp\\tCover\\tchrname' > summary.tsv
     for file in *.copynumber.csv; do
       chrname=`echo \$file | sed -e 's/^rm\\.out_//' -e 's/.copynumber.csv\$//'`
       awk -v chrname=\$chrname 'BEGIN{OFS="\\t"} NR>1 && /^[^#]/ {print(\$0, chrname)}' \$file
     done >> summary.tsv
       """
     }
   #+END_SRC

** Summary tables and figures

   #+BEGIN_SRC groovy :tangle ../main.nf
     process summarise {
       publishDir "${params.outdir}/summarise", mode: 'copy'

       input:
       file 'summary.tsv' from repeatmaskerSummaryTable

       output:
       set 'summary.bycontig.tidy.tsv', 'summary.tidy.tsv'

       """
     #!/usr/bin/env Rscript
     library(ggplot2)
     library(dplyr)
     library(tidyr)
     library(magrittr)

     data <- read.table('summary.tsv', header=TRUE) %>%
             separate(Family, into=c("Family", "Subfamily"), sep="/") %>%
             group_by(chrname, Family, Subfamily) %>%
             summarise(fragment.count = sum(Fragments), length = sum(Total_Bp)) %>%
             unite("Family", Family, Subfamily, sep="/")

     write.table(data, file='summary.bycontig.tidy.tsv')

     data <- read.table('summary.tsv', header=TRUE) %>%
             separate(Family, into=c("Family", "Subfamily"), sep="/") %>%
             group_by(Family, Subfamily) %>%
             summarise(fragment.count = sum(Fragments), length = sum(Total_Bp)) %>%
             unite("Family", Family, Subfamily, sep="/")

     write.table(data, file='summary.tidy.tsv', row.names = FALSE)
       """
     }
   #+END_SRC

   #+BEGIN_SRC groovy :tangle ../main.nf
     workflow.onComplete {
         log.info "Pipeline completed at: $workflow.complete"
         log.info "Execution status: ${ workflow.success ? 'OK' : 'failed' }"
     }
   #+END_SRC
